---
layout: page
title : About
permalink: /about/
---

<h2>About me</h2>
<p>Benjamin Feuer</p>
<br>
<center><p ><strong><span class="manual">AI Safety, Robustness and Explainability</span></strong></p></center>
<br>
<p><img src="/assets/ben.JPG" style="margin:2px 10px" width="150px" height="200px" align="right">
 With a dual background in humanities and computer science, I bring unique perspectives to my work as a researcher, developer and communicator. My work has been presented at AAAI and ICML. For more details, see my recent <a href="https://scholar.google.com/citations?user=VPXu100AAAAJ&hl=en">publication history</a> and <a href="https://www.linkedin.com/in/benjaminfeuer">LinkedIn Profile</a>.</p>

<ul>
  <li><strong>Computer Science Ph.D. Researcher at <a href="https://chinmayhegde.github.io/lab/">New York University</a></strong>. <a href="https://scholar.google.com/citations?user=VPXu100AAAAJ&hl=en">My research</a> centers on AI safety, explainability and robustness.</li>
  <li><strong>I maintain <a href="https://github.com/penfever/vlhub/">VL Hub</a>,</strong> a vision-language pretraining framework which integrates CLIP pretraining, LiT-Tuning, CoCa, conventional timm vision models and SimCLR contrastive models into a single test-train-eval framework, making it easier to compare models across architectures and objectives.</li>
  <li><strong>I created the <a href="https://github.com/penfever/archetype/">ArcheType</a></strong> method, which uses large language models to help with data cleaning and integration.</li>
</ul>
 <a href="http://linkedin.com/in/benjaminfeuer"><i class="fa fa-linkedin"></i></a> &nbsp; &nbsp; &nbsp;<a href="http://github.com/penfever"><i class="fa fa-github"></i></a>