<!DOCTYPE html>

<html>

<head>
  <title>Benjamin Feuer</title>

  <meta name="description" content="Benjamin Feuer is an AI and Machine Learning Ph.D. researcher at Stanford University.">
  <meta name="keywords" content="Benjamin Feuer, Ben Feuer, penfever, machine learning, NYU, Columbia, Wesleyan University, New York University, Stanford University, computer science, CS, AI, artificial intelligence, data-centric ML, data engineering, large language models, LLMs, distributional robustness, VLMs, vision language models, object detection, zero-shot, in-context learning, tabular ML, tabular deep learning, semantic segmentation">
  <meta name="author" content="Benjamin Feuer">
  <meta charset="UTF-8">

  <link href="./css/normalize.css" rel="stylesheet" type="text/css">
  <link href="./css/screen_stanford.css" rel="stylesheet" type="text/css">
  <link href="./css/syntax.css" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" href="./img/w.png">
  <link rel="stylesheet" href="./css/academicicons/css/academicons.min.css"/>
  <link href="./css/fontawesome/css/all.css" rel="stylesheet">

  <!-- Google Analytics Script -->
  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-28340066-1']);
  _gaq.push(['_trackPageview']);
  (function() {
          var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
          ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
          var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
  </script>
</head>


<body>
    <div class="container">

    <header>
        <div class="header-left">
            <img src="./assets/ben_upd.jpeg" alt="Benjamin Feuer" height="150" style="border-radius: 5px;">
        </div>
        <div class="header-right">
            <!-- ========== -->
            <!-- Name -->
            <!-- ========== -->
            <h1><a href="./index.html">Benjamin Feuer</a></h1>

            <!-- ========== -->
            <!-- Icons -->
            <!-- ========== -->
            <p class="pre_icon_padding"></p>
            <p class="one_icon">
              <a href="http://github.com/penfever" target="_blank">
                <i class="fab fa-github"></i>
            </p>
            <p class="one_icon">
              <a href="http://twitter.com/feuerbenjamin" target="_blank">
                <i class="fab fa-twitter"></i>
            </p>
                        <p class="one_icon">
              <a href="https://www.linkedin.com/in/benjaminfeuer/" target="_blank">
                <i class="fab fa-linkedin"></i></a>
            </p>
            <p class="one_icon">
              <a href="https://scholar.google.com/citations?user=VPXu100AAAAJ&hl=en" target="_blank">
                <i class="ai ai-google-scholar"></i></a>
            </p>
            <p class="one_icon_bigger">
              <a href="./assets/ben-feuer-cv-07-15-25.pdf" target="_blank">
                <i class="ai ai-cv"></i></a>
            </p>

            <!-- ========== -->
            <!-- Header/Tagline -->
            <!-- ========== -->
            <!-- <p class="header-tagline">
                Machine learning at 
                <a href="https://nyu.edu/"> NYU </a>
            </p> -->

            <!-- ========== -->
            <!-- Current position blurb -->
            <!-- ========== -->
            <p class="bio">
            Hello! I am a Postdoctoral Researcher at Stanford University working with Ludwig Schmidt's Lab. I completed my Ph.D. in Computer Science and Engineering at NYU as a member of the DICE Lab. I am also a researcher for AI startup Oumi.AI. Previously, I received an BA in Film Studies from Wesleyan University, an MFA in Screenwriting from Columbia University, and an MS in Computer Science from New York University. My awards include a NeurIPS Spotlight award and the Deborah M. Rosenthal Award (Best CS Qualifying Exam).
            </p>
        </div>
    </header>

    <section id="about">
        <div class="section-right offset">

            <!-- ========== -->
            <!-- Research/Education Bio Paragraphs -->
            <!-- ========== -->

            <p class="bio">
            <strong>Research: </strong>
            I have wide-ranging research interests; some of my recent topics include data-centric factors in machine learning systems, robust LLM benchmarking, evaluation and alignment, and scalable data integration for very large databases.
            </p>

            <p class="bio">
            <strong>Education: </strong>
            I am currently a Postdoctoral Researcher at Stanford University working with 
            <b><a href="https://profiles.stanford.edu/ludwig-schmidt">Ludwig Schmidt's group</a></b>. I completed my PhD in Computer Science
            at New York University, advised by
            <b><a href="https://chinmayhegde.github.io">Chinmay Hegde.</a></b>
            Previously, I studied at Columbia University and Wesleyan University. Other frequent collaborators include 
            <b><a href="https://goldblum.github.io">Micah Goldblum</a></b>
            and <b><a href="https://crwhite.ml">Colin White</a></b>
            and <b><a href="https://jpdickerson.com">John P Dickerson</a></b>
            and <b><a href="https://engineering.nyu.edu/faculty/juliana-freire">Juliana Freire</a></b>.
            </p>

        </div>
    </section>

    <section id="news">
        <div class="section-title">
            <h2>News</h2>
        </div>
        <div class="section-body" style="overflow-y:auto;height:450px;">
            <ul>
                <li class="news">
                    <span class="news-name">
                        <b>2025/7/15</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2507.01544">New first-author paper</a></b> proposing MARVIS (Modality Adaptive Reasoning over VISualizations), a training-free method that enables even small vision-language models to predict any data modality with high accuracy..
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2025/6/24</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://www.open-thoughts.ai/">New paper</a></b> on Open Thoughts, introducing strong public data recipes for reasoning models.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2025/5/19</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2505.19259">New paper</a></b> on large reasoning models for agriculture, introducing AgReason, the first expert-curated open-ended science benchmark with 100 questions for agricultural reasoning.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2025/3/1</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="http://sites.computer.org/debull/A25mar/p3.pdf">New paper</a></b> published in IEEE Data Engineering Bulletin on data systems and engineering.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2025/01/31</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2409.15268">New paper</a></b> (+
                      <a href="https://livebench.ai/">code</a>). LiveBench is a leading benchmark for foundation models; unlike traditional benchmarks, questions and categories evolve over time. Featured in Gemini, Qwen and Deepseek technical reports.
                      <b><i>ICLR 2025</i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2025/01/31</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2409.15268">New first-author paper</a></b> (+
                      <a href="https://github.com/penfever/sos-bench/">code</a>). Do LLM-judge preferences translate to progress on other, more concrete metrics for alignment? No, because LLM judges exhibit implicit biases; without being prompted, they reweight existing criteria and implement their own standards by which they evaluate provided judgment criteria. This work emphasizes the importance of blending ground truth and LLM judge evaluations for foundation models.
                      <b><i>ICLR 2025</i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2025/01/31</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2412.04653">New paper</a></b>. We demonstrate a distortion-free watermarking method for images, based on a combination of a diffusion model's initial noise and generated Fourier patterns.
                      <b><i>ICLR 2025</i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2024/9/28</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2406.17720">New first-author paper</a></b> (+
                      <a href="https://baskargroup.github.io/Arboretum/">code</a>) describing BioTrove, the largest publicly accessible dataset designed to advance AI for biodiversity applications. We also release a suite of CLIP models trained using a subset of 40 million captioned images. We introduce several new benchmarks for rigorous assessment, report accuracy for zero-shot learning, and evaluations.
                      <b><i>NeurIPS 2024 (Spotlight), USDA Highlighted Project</i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2024/9/28</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2402.11137">New first-author paper</a></b> (+
                      <a href="https://github.com/penfever/TuneTables/">code</a>) describing TuneTables, a novel tabular classification and regression model which is competitive with boosted trees, and can scale to problems of any size. 
                      <b><i>NeurIPS 2024</i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2024/6/24</b>
                    </span>
                    <span class="news-desc">
                        <b><a href="https://arxiv.org/abs/2406.19314">New paper</a></b> (+
                        <a href="https://livebench.ai/">code</a>) introducing LiveBench, a benchmark for LLMs designed with test set contamination and objective evaluation in mind. LiveBench is designed to limit potential contamination by releasing new questions monthly, as well as having questions based on recently-released datasets, arXiv papers, news articles, and IMDb movie synopses. Each question has verifiable, objective ground-truth answers, allowing hard questions to be scored accurately and automatically, without the use of an LLM judge. 
                      <b><i>Featured in Venture Beat</i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2024/2/13</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/f06d5ebd4ff40b40dd97e30cee632123-Abstract-Datasets_and_Benchmarks.html">New paper</a></b> (+
                      <a href="https://github.com/naszilla/tabzilla">code</a>) benchmarking the performance of tabular algorithms on the largest suite of datasets to date. 
                      <b><i>NeurIPS 2023 (Datasets and Benchmarks)</i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2023/11/07</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2311.04016">New first-author paper</a></b> studying the effects of two important dataset-level constituents: label set design, and class balance. 
                      <b><i>NeurIPS 2023 (1st Workshop on Attributing Model Behavior at Scale) </i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2023/10/28</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://openreview.net/forum?id=b0OhN0ii36">New first-author paper</a></b> investigating sketching and feature-selection methods for prior-fitted networks. 
                      <b><i>NeurIPS 2023 (Second Table Representation Learning Workshop) </i></b>.
                    </span>
                </li>
                <li class="news">
                    <span class="news-name">
                        <b>2023/10/27</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/abs/2310.18208">New first-author paper</a></b> (+
                      <a href="https://github.com/penfever/archetype">code</a>) introducing ArcheType, a simple, practical method for context sampling, prompt serialization, model querying, and label remapping, which enables large language models to solve CTA problems in a fully zero-shot manner. 
                      <b><i>VLDB 2024</i></b>.
                    </span>
                </li>                
                <li class="news">
                    <span class="news-name">
                        <b>2023/08/01</b>
                    </span>
                    <span class="news-desc">
                      <b><a href="https://arxiv.org/pdf/2308.03821">New first-author paper</a></b> introducing JANuS (Joint Annotations and Names Set), a collection of four new training datasets with images, labels, and corresponding captions, and conducting controlled investigations of factors contributing to robustness in image classification.
                      <b><i>TMLR 2023</i></b>.
                    </span>
                </li> 
        </div>
        <!--Note: I only have the following in order to add a correctly formatted "section-spacer" line...-->
        <div class="section-right offset">
        </div>
    </section>

    <section>
        <div class="section-title">
            <h2>Publications</h2>
        </div>
        <div class="section-right offset">
            A full list of my publications can be <a href="https://scholar.google.com/citations?user=VPXu100AAAAJ&hl=en">found here</a>.
        </div>
    </section>


    <footer>
        <p>
            Check me on <a href="https://github.com/penfever">GitHub</a> &amp;
            <a href="https://twitter.com/feuerbenjamin">Twitter</a>.  Check my current 
            <a href="./assets/ben-feuer-cv-07-15-25.pdf">CV.</a>  Site layout inspired by <a href="https://willieneis.github.io/">Willie Neiswanger</a>.
        </p>
    </footer>


</body>
</html>